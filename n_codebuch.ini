
##Sonderzeichen, die hier nicht vorkommen sollten: „"–

###############################################################################################
###############
############### Procedure
###############


[Methode_Menu]
Select a method
What kind of procedure do you wish to perform?
Dummy Table:#A crosstable is created in which the occurrence of all values of a multinomial variable within groups defined by a group variable are noted.##Co-Occurrence Matrix:#A NxN-Matrix for a multinomial variable is created. The matrix tells whether certain values appear together within groups defined by a group variable. Alternatively, the co-occurrence of dummies may be calculated.##Social Network:#An adjacency matrix is created which may be read and edited in visone (visone.info). The social network visualizes the relations between two categories (sender and object). This method may also be used on the data on nationalist appeals (Nino).##Merge Files: Add variables from one file to another one. Neither of the files has to be sorted in any way and an unlimited number of key-variables may be used.##Aggregate Dataset:#Aggregate data on group level. Different methods for aggregation (mean, sum, maximum...) may be used.
TT:Transform Data
-So1:Sort cases
-So2:Rearrange variables
-So3:Rename variables
-S1:Select Subset of Cases
M:Merge datasets
-M2:Add cases from another table
-M3:Merge many tables with same variables
-M1:Add Variables from key-dataset
S:Extract Subset from Data
-S1:Select Cases
-S4:Split table to several subsets
-S3:Random sample of cases
-S2:Select Variables
R:Reshape Datasets
-R1:Create Dummy Table
-R2:Reshape Dummy table to slim table
A:Aggregate Data
-A1:Aggregate Cases to groups
-A2:Aggregate variables (calculation)
-A3:Calculate Entropy of Groups
T:Recode Variables
-T1:Transform Timestamps
-T2:Transform scale to groups
#
C:Co-Occurrence
-C1:Create Co-Occurrence Matrix for a Multinomial Variable
-C2:Create Co-Occurrence Matrix from Dummy-Table
V:Social Network Visualization
-V1:Create Social Network Visualization from two variables
Ts:Time series
-Ts1:Detect Peaks
-Ts2:Flatten Moving Average
-Ts3:Create Gliding Window
-Ts4:Detect Gaps in Timeseries
-Ts7:Normalize Timeseries
-Ts5:Pattern Detection in continuous data
-Ts6:Synchronize Event Data
Se:Sequence Analysis
-Se1:Find common sequences
-Se2:T-Pattern analysis
-Se3:Grammar Induction
CAn:Cluster Analysis
-An1:Cluster Analysis of Count Data (HECANE)
-An3:K-Means Cluster Analysis
-An4:Multigroup Cluster Analysis (k-means)
An:Other Analyses
-An2:Analysis of Entropy
-An5:Analysis of attention and focus (Timeseries)
Vi:Visualize Data
-Vi1:Heat Map of table
-Vi2:X-Y Line Plot
RT:Reliability Testing
-RT1:Test interrater reliability
NCCR:NCCR III Data reshaping
-NCCR1:Add Populism Variables
-NCCR2:Calculate hours per coder
-NCCR3:Match up Media Content and Panel Survey
-NCCR4:Match up Media Content and Cross Sectional Survey
GGCRISI:GGCRISI Data aggregation in one step
#
U:Get Universe of n-grams
Co:Create Corpus
-C:Create Corpus from Codesheets and Textfiles
-CT:Create Corpus from a folder of Textiles
Inspect:Inspect Corpus
-In1:Find context of Regex
SVM:Support Vector Machine
-SVM_Train:Train SVM
-SVM_Test:Test and Adjust SVM
-SVM_Apply1:Apply SVM to unknown corpus
-SVM_Apply2:Apply SVM to folder of textfiles
Bay:Naive Bayes Classification
-NBC_Train:Train NBC with cross-validation
-NBC_Test:Test and adjust NBC
-NBC_Apply1:Apply NBC to unknown corpus
-NBC_Apply2:Apply NBC to folder of textfiles
Dupli:Find duplicates by ngram shingling
-Dupli1:Find duplicates in Corpus
-Dupli2:Find duplicates in folder of textfiles


#########Project: getting Aeglos to work in Nogrod

Tool:Text analysis tools
-Tool1:Create Term-Document Matrix
-Tool2:Word co-occurrence and Term Mapping
-Tool3:Split collocated textfiles
-Tool4:Test Language/Encoding Settings
Dict2:Dictionary based annotation
Dupli:Find duplicates by ngram shingling



############################################################
# Variables which are used in several procedures

[In_Header]
Variable Names in Header
Does the first line of the file contain the names of the variables?
If you select 'Yes', the first line of the file will be used to name the variables. Repetitions of the same name will be numbered (01-99). If you select 'No', the variables are numbered (Var01-Var99)
1:Yes
0:No


[In_Sep]
Separator
What kind of separator is used to mark the end of a cell?
The separator is a fix character which is used to mark the end of a cell within a row. If you copy-paste the data from Excel, it is always a tabulator. For CSV-Files it may be a semicolon or Comma.
1:Tabulator / Tabstopp
2:Semicolon (;)
3:Comma (,)
4:Quote-Semicolon-Quote (";")

##5:Excel-Spreadsheet


[Out_Header]
Store Variable Names?
Should the names of the variables be written on the first line (header) of the file?
If you choose 'Yes', the names of all variables are written on the firs line.
1:Yes
0:No


[Out_Sep]
Separator
What kind of separator should be used to mark the end of a cell?
The separator is a fix character which is used to mark the end of a cell within a row. If you copy-paste the data from Excel, it is always a tabulator. For CSV-Files it may be a semicolon or Comma.
1:Tabulator / Tabstopp
2:Semicolon (;)
3:Comma (,)

##5:Excel-Spreadsheet


[Out_Attach]
Attach or create new file?
Do you want to attach the report to an existing file or create a new one?
-
w:New File
a:Attach to existing



########################################
# Dummy

[Dummy_Input]
Input Table
which file contains the data from which a dummy table is to be generated?
The file should be a textfile containing a table in a fixed format (i.e.: with cell separators)


[Dummy_Case]
Grouping Variable
Which variable contains the row names of the dummy table.
You see a list of all variables which are available in the file. Select the one multinomial variable which contains the names of the groups you wish to create a dummy table with.


[Dummy_MN]
Multinomial Variable
The values of this variable will constitute the row names in the dummy table.
You see a list of all variables which are available in the file. Select the one multinomial variable which contains the values to create dummies of.


[Dummy_Mode]
Method for cell contents
Select the method to calculate the content of the cells of the dummy table.
Dichotomous:#If the value is present within the group, the cell has the value 1, else the value is 0.##Count:#The cell contains the exact number of times the value is present within the group.##Logarithm:#The cells contain the logarithm of the number of times a value is present within a group. Useful for cell counts > 100.
dicho:Dichotomous (1/0)
anz:Count (N)
log:Logarithm (log(N+1))


[Dummy_MinCas]
Minimal number of elements per group
On each row, at least this amount of elements is expected. Rows with fewer elements are discarded.
Optionally, groups with too few elements may be discarded. This is useful if many poorly used groups are present.##Please note: Choosing the method 'count' results in more occurrences of a value than 'dichotomous'.
0:0
1:1
2:2
3:3
4:4
5:5
6:6
7:7
8:8
9:9
10:10
15:15
20:20
25:25
30:30
40:40
50:50

[Dummy_MinAnz]
Minimal number of occurrences per value
In each column, at least this number of items is necessary.
Optionally, values which are chosen too rarely may be excluded.##Please note: Choosing the method 'count' results in more occurrences of a value than 'dichotomous'.
0:0
1:1
2:2
3:3
4:4
5:5
6:6
7:7
8:8
9:9
10:10
15:15
20:20
25:25
30:30
40:40
50:50

[Dummy_Output]
Output file
In which file should the dummy table be written? (standard extension: .txt)



########################################
# Co-Occurrence 


[Cooc_Input]
Input Table
Which file does contain the data to work with?
The file should be a textfile containing a table in a fixed format (i.e.: with cell separators)


[Cooc_Case]
Group Variable
Which variable defines the groups in which values may co-occur?
Example: If you want to analyze the co-occurrence of actors within texts, the text ID would be the group variable.


[Cooc_MN]
Multinomial variable
Which variable contains the values which may or may not co-occur within the groups?
Example: If you want to analyze the co-occurrence of actors within texts, the ID of the actors would be the multinomial variable.


[Cooc_Mode]
Method for calculating co-occurrence
How are the contents of the cells calculated?
Dichotomous:#The cell contains 1 if the values co-occur in any group and 0 if they never co-occur.##Count:#The cell contains the number of times the values co-occur.##Probability:#The cell contains the conditional probability for values to co-occur.##Percent Agreement:#The cell contains the percent of groups in which both values are either present or absent together. Warning: Will be high for sparse matrices!##Inverse Probability:#Distance measure: Inverted probability of co-occurrence.##Sokal Distance:#Distance measure: Value between 0 and 1 for distance.##Euclid:Distance Measure: Euclidian Distance.
dicho:Dichotomous (1/0)
anz:count (N)
prob:Probability of co-occurrence (P(A|B)*P(B|A))
cprob:conditional probability (P(A|B))
einf:Percent Agreement (P(A&B)+P(-A&-B))
inv_prob:Inverse Probability of co-occurrence (Distanz)
sokal:Sokal-Distance
eukl:Euclid Distance
chi1:Chi Square
chi2:Cramer's V with direction


[Cooc_MinCas]
Minimal number of elements per group
Groups with less elements are excluded from the analysis.
-
0:0
1:1
2:2
3:3
4:4
5:5
6:6
7:7
8:8
9:9
10:10
15:15
20:20
25:25
30:30
40:40
50:50

[Cooc_MinAnz]
Minimal number of occurrences per value
Values which occur less times are excluded from the analysis.
-
0:0
1:1
2:2
3:3
4:4
5:5
6:6
7:7
8:8
9:9
10:10
15:15
20:20
25:25
30:30
40:40
50:50


[Cooc_Margin]
Store marginal sums
Should the marginal sums or frequencies be stored?
-
1:Yes, store margins
0:No margins



[Cooc_Output]
Output File
In which file should the co-occurrence matrix be written?
-



[Cooc_SSA]
Smallest Space Analysis
Should an R-Script be created which allows smallest space analysis (SSA) of the co-occurrence matrix?
-
1:Yes
2:No


########################################
# Co-Occurrence from Dummy Table


[CD_Input]
Input-Table
Which Table contains the dummy variables?
The table should contain variables which are either containing numbers or string variables. For numerical variables, all numbers other than 0 are counted as 1. All zeroes are counted as 0. For string variables, all strings are counted as 1 and all missing values are counted as 0.


[CD_Varlist]
Dummy Variables
Which Dummies should be used in the co-occurrence matrix?
Please select any number of variables to be counted as dummy variables. The list does not contain any invariant variables.



########################################
# Visone


[Visone_Input]
Input File
Which file contains the data to work with?
The input file should contain at least two multinomial variables, one denominating the subjects and one denominating the objects. Each row of the table is counted as one instance (i.e. one connection of subject and object).


[Visone_Subject]
Subject Variable
Which variable defines the subjects (origins of the arrows) of the social network?
The subject nodes are points in the network from which arrows point towards other points.



[Visone_Object]
Object variable
Which variable defines the objects of the social network?
The object nodes are points in the network which are pointed at.



[Visone_SubjObj]
Identical values for subjects and objects
Are the names of subjects and objects identically? (Does not influence the bidirectionality of the network)
You may always select 'Yes' for this variable. You may choose in Visone whether the subjects may be objects in the network. This choice is not affected by the answer to this question.
1:Yes
0:No



[Visone_Relation]
Relation Variable
Which variable defines the relation of subject and object?
The relation may be any numerical or string variable expressing the relation between the nodes.
9:No variable for relations


[Visone_Methode]
Method for relation
Each arrow has a value. How should this value be calculated?
Count:#The number of co-occurrences is used as relation.##Dichotomous:#The values of the relation may just be 1=present and 0=absent.##Inverse Count:#The number of co-occurrences is inverted (9/1+count) to create a distance measure.##Type:#The last occurring relation is counted as relation between each subject and object.##Mean:#The mean value of the relation variable is computed. Only works for numeric variables.##Sum:#The sum of values is computed. Only works for numeric variables.
anz:Count (N)
entf:Inverse Count
dicho:Dichotomous (1/0)
typ:Type (Multinomial relation variable)
mean:Mean Value (only metric relation variable)
sum:Sum (only metric relation variable)
all:All of the above (additional link table)


[Visone_Minanz]
Minimal occurrence
How many times does a node (subject and object) have to be present to be counted?
You may choose to limit the number of nodes by setting a lower limit for the number of occurrences.
0:0
1:1
2:2
3:3
4:4
5:5
6:6
7:7
8:8
9:9
10:10
15:15
20:20
25:25
30:30
40:40
50:50


[Visone_Output]
Output File
To which file should the adjacency matrix be written?
The name of the adjacency matrix to be loaded in visone afterwards.


[Visone_Out2]
Output of node counts
To which file should the count data for nodes be written? This information may be used as additional data.
An additional table which contains the number of occurrences for each node. Will be omitted if no name is entered.

[Visone_Out3]
Output of link values
To which file should the different values for links be written?
An additional table which contains the count, sum, and mean of links.



########################################
# Merge


[Merge_Dir]
Directory
Which directory holds all tables to be combined?
-


[Merge_Files]
Select tables to be merged
Select all tables you wish to combine to one table. If variables are different, all occurring variables will be used.
-


[Merge_Input1]
Main Table
Which table contains the main data which should be completed with information from another table?
The file should be a textfile containing a table in a fixed format (i.e.: with cell separators)



[Merge_Input2]
Key Table
Which table contains the additional information to be added to the main table?
The file should be a textfile containing a table in a fixed format (i.e.: with cell separators)


[Merge_Key1]
Key variables in main table
Which variables in the main table serve as key variables?
You may choose any number of variables. Corresponding variables have to be present in the key table as well.


[Merge_Key2]
Key variables in the key table
Which variables in the key table correspond to the key variables you see on the right?
The sequence of variables must not be altered. You have to add them in the same order. Otherwise, the merge won't work.


[Merge_Add]
Which variables should be added?
Which variables of the key table should be added to the main table?
You may select any number of variables.


[Merge_Out]
Output File
To which file do you want to write the new main table?
The name of the new main table may be identical with the main table which was loaded at the beginning. It is recommended, however, to create a new file.



########################################
# Elongate (Merge cases)


[Elong_Input1]
First Table
Which table contains the first part of the data which should be completed with cases from another table?
The file should be a textfile containing a table in a fixed format (i.e.: with cell separators)


[Elong_Input2]
Second Table
Which table contains the additional cases to be added to the first table?
The file should be a textfile containing a table in a fixed format (i.e.: with cell separators)


[Elong_Vars]
Variables in the resulting table
Which variables should be present in the output table?
You may choose any number of variables. If a variable only occurs in one table, it will have missing values for the cases of the other table.


[Elong_Out]
Output File
To which file do you want to write the new main table?
The name of the new main table may be identical with the main table which was loaded at the beginning. It is recommended, however, to create a new file.


########################################
# Aggregate Dataset


[Agg_Input]
Input Table
Which Table contains the data to be aggregated?
-


[Agg_Group]
Grouping Variables
Which variables are denominating the groups that should be aggregated?
-


[Agg_Var]
Variables to be aggregated
Which variables should be aggregated for each group?
-

[Agg_Method]
Method for aggregation
How should the aggregated values be calculated?
-
sum:Sum of values (only numeric data)
wsum:Weighted sum of values (only numeric)
mean:Mean of values (onle numeric data)
wmean:Weighted mean of values (only numeric)
max:Maximum value within group (only numeric data)
min:Minimum value within group (only numeric data)
nval:Number of valid (numeric) cases
all:Mean, Standard Deviation and Number of valid cases
wall:Weighted Mean, Standard Deviation and Number of valid cases
frequ:Most frequent value in data
first:First value in data
last:Last value in data
broad:Transform Dataset to broad format (copy all variables)


[Agg_Weight]
Weighting Factor
You indicated a weighted dataset. Which variable holds the weighting factor?
-


[Agg_Output]
Output File
To which file do you want to export the aggregated data?
-


########################################
# Calculate Entropy


[Entropy_Input]
Input Table
Which Table contains the data to be analyzed?
-



[Entropy_Group]
Grouping Variable
Which variable defines the groups within which the entropy is to be calculated?
-


[Entropy_Var]
Multinomial Variable
Which variable should be 
-


[Entropy_Mode]
List of reference
What should be taken as full population of elements for each group?
-
1:All elements across all groups
2:Only the elements within each group


[Entropy_Output]
Output File
To which file do you want to export the Entropy scores?
-


########################################
# Reshape Data


[Resh_Input]
Input Table
Which Table contains the data to be reshaped?
-



[Resh_Vars]
Variables to be condensed
Which of these variables should be condensed to one variable?
-



[Resh_Type]
Type of reshaping
How should the values be reshaped?
-
count:The values give the number of times the value occurs.
value:The values should be stored in a separate variable



[Resh_Output]
Output File
To which file do you want to export the reshaped table?
-



########################################
# Transform Timestamps


[TS_Input]
Input Table
Which Table contains the data to be transformed?
-



[TS_Var]
Input Variable
Which variable contains the timestamps?
-


[TS_Nvar]
Output Variable
How should the output variable be named? 
-


[TS_Informat]
Format of input variable
Please select the correct format for the input variable. You may also enter a strftime format (see question mark for information).
-
pys:Python Timestamp (String)
pyn:Python Timestamp (seconds)
ex:Excel Timestamp (days)
ger:German (dd.mm.yyyy)


[TS_Outformat]
Format of output variable
Please select the correct format for the output variable. You may also enter a strftime format (see question mark for information).
-
pys:Python Timestamp (String)
pyn:Python Timestamp (seconds)
ex:Excel Timestamp (days)
dec_h:Decimal time of day (h.nnn)
ger:German (dd.mm.yyyy)


[TS_Int]
Variable level
For numerical output formats: How should the values be stored?
-
ic:Integer values (cut off decimals)
ir:Integer values (rounded)
fl:Floating numbers (decimals)


[TS_Output]
Output File
To which file do you want to export the table with added timestamp variable?
-


########################################
# Grouping

[Group_Input]
Input Table
which file contains the data from which a dummy table is to be generated?
The file should be a textfile containing a table in a fixed format (i.e.: with cell separators)


[Group_Var]
Scale variable
Wich Variable contains the numeric variable to be grouped (e.g. Timestamps / Indices)?
You see a list of all variables which are available in the file. Select the one metric variable which should be grouped.

[Group_NVar]
Output Variable
Wich Variable should contain the group values?
-


[Group_Mode]
Which method should be used to group the variable?
Select the method to generate the groups.
-
equal:Equally sized groups (e.g. Median / Quantiles)
fixed:Equal steps between cuts (e.g. weeks, hours...)
tails:Tails of the distribution (e.g.: outside the 95% confidence interval)


[Group_Equal]
Size of groups
Which portions should be generated?
-
2:Median Split (2x50%)
3:Terzile (3x33%)
4:Quartile (4x25%)
5:Qintile (5x20%)

[Group_Fixed]
Size of step
How many units of the variable are one step?
-


[Group_Tails]
Size of the tails
Which confidence interval do you want to use (two-sided for all choices)?
-
50:50%
80:80%
90:90%
95:95%
97.7:97.5%
99:99%


[Group_Output]
Output file
In which file should the dummy table be written? (standard extension: .txt)
-



########################################
# Sort dataset


[Sort_Input]
Input Table
Which Table should be sorted?
-


[Sort_Var]
Sort cases by
Select the variables to sort the data by. The order of variables defines the sort hierarchy
-


[Sort_Dir]
Sort direction
Should the data be sorted ascending (small values first) or descending (large values first)
-
1:Ascending
2:Descending


[Sort_Output]
Output Table
In which file should the sorted table be stored?



########################################
# Rearrange Variables


[Rear_Input]
Input Table
Which Table should be rearranged?
-


[Rear_Var]
New List of Variables
Add variables in the order you wish them to be. Left out variables will be deleted. Double variables will be numbered (X01, X02...)
-


[Rear_Output]
Output Table
In which file should the changed table be stored? (Default is input file)

########################################
# Rename Variables


[Ren_Input]
Input Table
Which Table should be rearranged?
-


[Ren_Var]
Which variable should be renamed?
Select the variable to be renamed
-


[Ren_New]
New Name of the variable
Enter the new name of the variable.
-


[Ren_Other]
New name stored. Continue?
Do you want to rename other variables?
-
1:Yes, go on
2:No, save file


[Ren_Output]
Output Table
In which file should the changed table be stored?
-


########################################
# Subset of Dataset


[Sub_Input]
Input Table
Which Table contains the data to be divided?
-


[Sub_Group]
Grouping variables
Which variables are denominating the groups that should be used for selection?
-


[Sub_Val]
Values for subset?
Which values of these variables should be used in the subset?
-


[Sub_Output]
Output File
To which file do you want to export the subset?
-


[Sub_Split]
Output File (without suffixes)
To which files do you want to export the subset? The values will be appended as suffix.
-



########################################
# Random Subset


[Sub_Random_Number]
Number of cases
How many cases should be selected randomly from the table?
-



########################################
# Subset of Dataset Variables



[Sub_Vars]
Selection of Variables
Which variables should be present in the final dataset? The order of the list will be the order of columns.
-




########################################
# Easy Calculation


[Calc_Input]
Input Table
Which Table contains the data to be used for calculation?
-


[Calc_Vars]
Variables to be aggregated
Which variables should be used in the calculation?
-


[Calc_Method]
Method for calculation
Which method should be used for calculation?
-
sum:Sum of all values
mean:Mean of all values
max:Maximum value
min:Minimum value
prod:Product of all values
concat:Concatenate (String variables)


[Calc_New]
Name of output variable
What is the name of the new variable?
-


[Calc_Output]
Output File
To which file do you want to export the dataset including the new variable?
-


########################################
# Time Series Peaks


[Peak_Input]
Input-Table
Which Table contains the time series data for calculation?
-


[Peak_Time]
Time variable
Which variable contains the timestamps (numeric)?
-


[Peak_Series]
Measurement variable
The peaks for which variable should be identified??
-


[Peak_Var]
Output Variable
To which variable should the values be written?
-


[Peak_Direction]
Detect peaks
Which peaks should be detected?
-
1:Positive and negative peaks
2:Only positive peaks
3:Only negative peaks


[Peak_Threshold]
Threshod for peak
Which threshold should be reached to count a value as part of a peak?
-
0:No Confidence interval. Detect all peaks.
50:Value outside the 50% confidence interval
80:Value outside the 80% confidence interval
90:Value outside the 90% confidence interval
95:Value outside the 95% confidence interval
97.5:Value outside the 97.5% Confidence interval
99:Value outside the 99% confidence interval



[Peak_Mode]
Mark as peak
How should the peak be marked?
-
1:Mark the whole area
2:Mark only the maximum of the peak



[Peak_Output]
Output File
To which file do you want to export the dataset including the new variable?
-


########################################
# Time Series Flatten


[Flat_Input]
Input Table
Which Table contains the time series data for calculation?
-


[Flat_Time]
Time variable
Which variable contains the timestamps (numeric)?
-


[Flat_Series]
Measurement variable
Which variable contains the time series to be flattened?
-


[TS_Show]
Preview
Click the button to get a preview of the time series
-
1:Preview


[Flat_Window]
Width of the gliding window
How many units should the window span?
The curve will be flattened by calculating gliding means. Each value of the curve is separated to a gliding mean value and a deviation.


[Flat_Var]
Moving Average Variable
To which variable should the smoothed series be written?
-

[Flat_Peaks]
Peak Variable
To which variable should the deviations from the smooth curve (small peaks) be written?
-


[Flat_Output]
Output File
To which file do you want to export the dataset including the new variable?
-



########################################
# Gliding Window


[Glide_Input]
Input-Table
Which Table contains the time series data for calculation?
-


[Glide_Time]
Time variable
Which variable contains the timestamps (numeric)?
-


[Glide_Units]
Width of the gliding window
How many units does the gliding window span?
-
1:1
2:2
3:3
4:4
5:5
6:6
7:7
10:10
15:15
20:20
30:30
50:50


[Glide_Position]
Position of the identifier
Which value within the window should be the denominator?
-
1:First element
2:Middle element
3:Last element


[Glide_Var]
Position Variable
Which variable should contain the window position?
-


[Glide_Output]
Output File
To which file do you want to export the dataset including the new variable?
-



########################################
# Gap detection


[Gap_Input]
Input-Table
Which Table contains the time series data for calculation?
-


[Gap_Tvar]
Timeseries Variable
Which variable holds the continuous time series variable?
-


[Gap_Gvar]
Group Variable
If there are several parallel time series in this table, what is the grouping variable?
-
res_nogroup:[No Grouping variable]


[Gap_Length]
Duration of a gap
What is the minimal gap in the time series variable that should count as a gap?
-


[Gap_Sort]
Sort by timestamps?
Should the dataset be sorted or do you want to retain the current order?
-
1:Yes, sort dataset
0:No, retain current order


[Gap_Store]
Group variable
What variable should the running number of segments between gaps be stored in?


[Gap_Output]
Output File
To which file do you want to export the dataset including the new variable?
-


########################################
# Normalize Continuous Time series


[NTS_Input]
Input-Table
Which Table contains the time series data for calculation?
-


[NTS_Tvar]
Time Stamp Variable
Which Table contains the time stamps in a numerical format?
-

[NTS_Gvar]
Grouping Variable
If there are several distinct Time series, which variable describes the group or session?
-
res_nogroup:No grouping variable


[NTS_Zero]
Relative Timestamps
Should the first action be set to zero to get relative timestamps?
-
0:No, use absolute time
1:Yes, use relative time stamps for each group


[NTS_Duration]
Interval length
How long should the standardized interval between measurements be?
-


[NTS_Vars]
Select variables
Which variables should be extended to the new format?
-


[NTS_Method]
Aggregation method
How should the value for unobserved time points and overlaps be computed?
-
proxy:Use most proximal value
recent:Use most recent value
mode:Use last mode value
interpol:Interpolate values (only numerical)


[NTS_Out]
Output File
To which file should the normalized time series be written?
-



########################################
# Pattern detection


[PD_Input]
Input-Table
Which Table contains the time series data for calculation?
-


[PD_Pattern]
Pattern Table
Which file contains the pattern? (Format: just numbers in a text file. One Number per line)
-


[PD_Patterns]
Patterns Table
Which file contains the patterns to be used? (Format: Table with one pattern per column)
-


[PD_Series]
Measurement variable
For which variable should patterns be identified?
-


[PD_Series_mult]
Measurement variables
For which variables should parallel patterns be identified?
-


[PD_Pattern_mult]
Parallel patterns
Which patterns should be matched to the variables? (same order as sequence variables)
-


[PD_Var]
Output Variable
To which variable should the values be written?
-


[PD_Minlen]
Minimum length of patterns
Please enter the minimal number of elements to be considered as a pattern
-


[PD_Maxlen]
Maxlen length of patterns
Please enter the maximal number of elements to be considered as a pattern
-


[PD_Method]
Output Method
What should the output variable contain?
-
1:Continuous correlation with pattern
2:Dichotomous indication of pattern match
3:Altitude of matched patterns (arithm. mean)
4:Altitude of matched patterns (geom. mean)
5:Continuous correlation, altitudes, and length (4 variables)


[PD_Cutoff]
Cutoff-Value
What size should the correlation be to be counted a match?
-



[PD_Output]
Output File
To which file do you want to export the dataset including the new variable?
-



########################################
# Synchronize Event Data


[Syn_Input]
Input-Table
Which Table contains the time series data to be synchronized?
-


[Syn_Var]
Variables to be synched
Which variables are to be synchronized? Only Dummy Variables are eligible.



[Syn_Frame]
Maximal allowable frame shift
How much frame shift is to be expected between the time series?


[Syn_Meas]
Measure of similarity
What measure should be used to compute the similarity of time series?
-
percent:Percent Agreement
sokal:Sokal Distance (ignores mutual zeroes)
cohen:Cohen's Kappa (corrects for chance agreement)


[Syn_TS]
Retain Time Stamp?
Should a time stamp variable be included in the output? Due to frame shifts, the time stamps are probably unreliable.
-
notime:No, discard time stamp



[Syn_Out]
Output Table
To which table should the synchronized time series data be written?




########################################
# Find Sequences


[Seq_Input]
Input-Table
Which Table contains the sequence data for calculation?
-


[Seq_Svar]
Sequence Variable
Which variable holds the series of values to be sequenced?
-


[Seq_Tvar]
Time Variable
Which variable holds the information on the point in time for each case?
-
tmp_Time:There is no time variable


[Seq_Gvar]
Group / Person Variable
If there are sequences for multiple groups in the data, which variable holds the group information?
-
tmp_Group:There is only one sequence



[Seq_Length]
Length of the Sequence
How long should the sequences become (maximum)?
-
2:2
3:3
4:4


[Seq_Omit]
Omission of one value
May one value be omitted within the sequence?
-
1:Yes
0:No



[Seq_Output]
Output File
To which file do you want to export the dataset including the new variable?
-


[Seq_Mode]
Ouput Mode
How should the output table be organized?
-
1:Long Table (one variable for all sequence types)
2:Broad Table (one variable for each type)



########################################
# T-Pattern Analysis

[Tpat_Input]
Input Table
Which table holds the sequence data to be analyzed
-


[Tpat_Time]
Time Variable
Which Variable holds the timestamps or event numbers?
-
notime:No Time variable. The data is in correct order


[Tpat_Group]
Group Variable
Which variable denotes the sequence (if more than one sequence in the dataset)?
-
nogroup:Only one sequence



[Tpat_Vars]
Events
Which variables hold the dummy variables for which patterns should be identified?
-


[Tpat_Level]
Level of Significance
How large is the probability of error allowed to be?
-


[Tpat_Long]
Treat long events as single event
Do you want to treat long series of a single event to be treated as one instance of this event?
-
1:Yes
2:No, each instance is to be regarded separately


[Tpat_Out]
Output Table
To which table should the T-Pattern Report be written?
-



########################################
# Grammar Induction

[Gind_Input]
Input Table
Which table holds the sequence data to be analyzed
-


[Gind_Symbol]
Symbol Variable
Which Variable holds the Symbols making up the sequence?
-


[Gind_Group]
Group Variable
Which variable denotes the sequence (if more than one sequence in the dataset)?
-
nogroup:Only one sequence



[Gind_Time]
Time Variable
Which variable denotes the time to sort the dataset with?
-
notime:No time variable. The dataset is sorted correctly




[Gind_Glitch]
Exclude glitches
How many times should a symbol be repeated to count as a symbol?
-



[Gind_Rep]
Aggregate repetitious patterns
Should repeating symbols and n-grams of symbols be aggregated?
-
1:Yes
0:No


[Gind_Subs]
Eliminate subsumed patterns
Should patterns be removed if they are part of a larger pattern?
-
1:Yes
0:No
2:Remove larger one instead


[Gind_Rep_Min]
Minimal length of repeting n-gram
How long is the minimal n-gram that should be checked for repetitions (Default: 1 = single symbol)
-



[Gind_Rep_Max]
Maximal length of repeting n-gram
How long is the maximal n-gram that should be checked for repetitions (Default: 1 = single symbol)
-


[Gind_Len_Min]
Minimal length of sequence to be extracted
How long should the sequences be (Default: 3)?
-



[Gind_Len_Max]
Maximal length of sequence to be extracted
How long are the sequences allowed to be at most (Default: 7)?
-


[Gind_Eta]
Eta-Coefficient
What is the threshold for decreasing probabilities (must be below 0.9)?
-





[Gind_Out]
Output of Sentences
Where should the sentences be written?
-







########################################
# Cluster Analysis of Count data


[Cluster_Input]
Input-Table
Which Table contains the count data to be clustered?
-


[Cluster_Vars]
Count Variables
Which variables should be clustered?
-


[Cluster_Miss]
Missing values
What should be done with cases containing missing values?
-
1:Remove case
2:Treat missing value as 0


[Cluster_Std]
Standardization
How should the data be standardized?
-
row:Row standardization
table:Table Standardization (Deviance Scores)


[Cluster_Output]
Output File
To which file do you want to export the plain text summary of the analysis?


[Cluster_Add]
Additional Outputs
Which additional outputs should be created?
-
ssa:Smallest Space Analysis (R-Script)
dendro:Dendrogram (R-Script)
hist:Detailed clustering history (Table)
dist:Cluster loadings for all Items (Table)
vector:Complete table of cluster vectors (Table)



########################################
# Multigroup and k-means Cluster Analysis



[Kcluster_Input]
Input-Table
Which Table contains the count data to be clustered?
-


[Kcluster_Group]
Group Variable
Which variable denotes the groups?
-

[Kcluster_Anz]
Number of Clusters
How many clusters should be created? Enter ranges in format: 2-5
-


[Kcluster_Direction]
Cluster rows or columns
Should the cases (rows) or variables (columns) be clustered?
-
1:Cluster cases (rows)
2:Cluster variables (columns)


[Kcluster_Vars]
Cluster Variables
Which variables should be used in the cluster analysis?
-


[Kcluster_Stand]
Standardize data
Should the data be standardized before clustering?
-
none:No standardization
rstand:Standardize Rows (cases)
rnorm:Normalize Rows (cases)
cstand:Standardize Columns (variables)
cnorm:Normalize Columns (variables)
tstand:Standardize Table
tnorm:Normalize Table


[Kcluster_Out]
Output Table
To which file is the report to be written?



########################################
# Analysis of Entropy

[Anent_Input]
Input-Table
Which Table contains the data to be analyzed (multinomial and group variables)?
-


[Anent_Group]
Grouping Variable
Which variable denominates the group?
-


[Anent_Multi]
Multinomial Variables
The Entropy of which nominal variables should be compared?
-


[Anent_Option]
Options
Special options for comparison of Entropy
-
boot:Bootstrapping (N=10'000)
comp:Comparison to random group assignment


[Anent_Output]
Output File
To which file is the report to be written?


########################################
# Analysis of Attention and Focus

[Focus_Input]
Input-Table
Which Table contains the content data? (contains: Date, Number of Texts, Occurring Issues and Actors)
-


[Focus_Date]
Date variable
Which variable denotes the day?
-
0:None. Use order as date.


[Focus_Dformat]
Date format
What format does the date have?
-
lfdn:Running number or excel day
ger:dd.mm.yyyy
eng:mm/dd/yyyy


[Focus_Ntext]
Number of text variable
Which variable specifies the number of texts per day?
-
count_em:Each line is one text. Count them.

[Focus_Weight]
Weighting number
Is there a weighting factor for each line?
-
no_weight:No weighting factor



[Focus_Issue]
Issue variables
Which variables contain the issue occurrences?
-


[Focus_Actor]
Actor variables
Which variables contain the actor occurrences?
-


[Focus_Direction]
Direction of the gliding window
Which day is the group denominator?
-
retro:Last day of the window (retrospective)
prosp:First day of the window (prospective)


[Focus_Window]
Length of the gliding window
How long should the gliding window be?
-
7:7 Days (recommended)
1:1 Day
30:30 Days


[Focus_Out]
Output File
To which file should the 3 timeseries be written?
-




########################################
# Visualize as heat map


[Heat_Input]
Input-Table
Which Table contains the table to be represented as a heat map?
-


[Heat_Vars]
Numeric variables
Which variables should be visualized?
-


[Heat_Sort]
Sort Variables and Cases by Value?
Should the table be sorted to show the highest values in the top-left corner?
-
0:No
1:Yes



[Heat_Maxsize]
Maximal Size of the plotting region
How large should the plotting region be allowed to become?
-
1: 400 x 300
2: 640 x 480
3: 900 x 600
4: 1200 x 900
5: 1500 x 1500
6: 2000 x 2000


[Heat_Color]
Color Scheme
How should the data points be colored?
-
bw: Black-White (Maximal Value is white)
ibw: White-Black (Maximal Value is black)
red: Red-Blue (Maximal value is blue)


[Heat_Log]
Logarithm
Should the logarithms of the values be used?
-
0:No
1:Yes


########################################
# Visualize X-Y


[Visu_Input]
Input-Table
Which Table contains the variables to be plotted against each other?
-

[Visu_X]
X Axis
Variable to be used for x-axis
-


[Visu_Y]
Y Axis
Variable to be used for y-axis
-

[Visu_Plot]
Plot X-Y
Generate plot
-
line:Line Plot
scat:Scatter Plot



########################################
# Nino


[Nino_Input]
Actors Table
Which actors Table is to be loaded?
The table should be either the output of Angrist or a table with similar properties and the same names of variables (especially APPTYPE, ID and UNIT_ID)


[Nino_Appeal]
Appeals Table
Which appeals Table is to be loaded?
The table should be either the output of Angrist or a table with similar properties and the same names of variables (especially ID and Unit_ID)


[Nino_Apptype]
Appeal-Type to export
Which appeal type should be used for this network? Only one may be used at the time.


[Nino_Methode]
Which method shall be used to name the edges (arrows)?
Each arrow will be assigned a value according to this method.
-
anz:Number of attributions (counting)
entf:Inverse number of attributuions (distance)
dicho:Dichotomous (present/absent)


[Nino_Out]
Output File
Where should the adjacency matrix be stored?
Please enter a filename or browse using the browse-button.

[Nino_Outtable]
Output File
Where should the corrected Appeal Table be stored?
Please enter a filename or browse using the browse-button.



########################################
#  Reliability Testing

[Reltest_Input]
Input Table
Please specify the table containing content analysis data. The table should contain one variable indicating the unit of analysis and one variable indicating the coder.
-


[Reltest_Unit]
Unit of analysis
Which variable contains the units of analysis?
-


[Reltest_Coder]
Coder identifier
Which variable contains the ID of the coders?
-



[Reltest_Var]
Test variables
Which variables are to be tested for interrater reliability?
-


[Reltest_Units]
Test cases
Which of the available cases do you want to test on?
-


[Reltest_Coders]
Compare Coders
Which of the available coders do you wish to compare?
-



[Reltest_Core]
Core coder?
Do you want to compare all coders toward one core coder? (e.g.: gold standard)
-
no_core:No core coder. Compare all



[Reltest_Method]
Method
Which coefficients are to be calculated?
-
PA:Percent Agreement (Holsti)
Kappa:Cohen's Kappa
Kappan:Brennan & Prediger Kappa
Pi:Scott's Pi (Kappa for multiple coders)
Lotus:Fretwurst Lotus (multiple coders)
SLotus:Standardized Lotus (muliple coders)
Alpha Nominal:Krippendorff's Alpha (nominal)
Alpha Ordinal:Krippendorff's Alpha (ordinal)
Alpha Metric:Krippendorff's Alpha (metric)
PRF:P-/R-/F-Value for Dichotomous Variables


[Reltest_Options]
Special Options
Do you want to include one of the following special options?
-
km:No Kappa value (Pi / Kappa) for invariant variables
cm:Count missing values as coding
min2:Demand a minimum of 2 comparisons
min5:Demant a minimum of 5 comparisons
rico:RICO (omitting coders)


[Reltest_Out]
Output File
To which file do you want to export the table containing all pairwise comparisons?
-


[Reltest_Report]
Report File
To which file do you want to export the detailed report on the reliability test?
-




########################################
# Universe of Words

[Univ_Input]
Input Directory
Which folder does contain the texts which contain all conceivable words?


[Encoding]
Encoding of the textfiles
How are the textfiles encoded?
-
latin-1:ANSI / Latin-1 / ASCII
utf-8:UTF8



[Univ_Subdir]
Include subdirectories?
Should sub-directories be included?
-
1:Yes
0:No


[Univ_Lang]
Language of texts
Which language are the texts in? Important for word stemming.
-
none:No stemming
de:German
eng:English
fr:French
it:Italian
nl:Dutch
pl:Polish


[Univ_Length]
Length of the n-grams
Up to how many words in a row should the n-grams span?
-
1:1 Word
2:2 Words
3:3 Words
4:4 Words
5:5 Words


[Univ_Sparse]
Lowest (highest) word frequency?
In how many texts should a word occur to be counted?
-
1:1% (99%)
5:5% (95%)
10:10% (90%)


[Univ_Out]
Output file?
Where should the wordlist be written?
-



########################################
# Corpus

[Corpus_Input]
Codesheets
Which file contains the codesheets to be completed?
-


[Corpus_Indic]
Textfiles
Which folder contains the textfiles to be used in this corpus? Leave blank if the full path is provided in the codesheet.
If the Textfiles are to be added to a codesheet, their filename has to be stored in a variable in the codesheets.



[Corpus_Outvar]
Name of Text Variable
Which name should the text variable have in the corpus?
-


[Corpus_OutID]
Name of Filenames Variable
Which name should the variable holding the filenames have in the corpus?
-


[Corpus_Subdir]
Include sub directories
Should sub directories be included in the collection of texts?
-
0:No
1:Yes



[Corpus_ID]
Name of Text ID
Which variable holds the text identifiers?
-


[Corpus_Out]
Output File
To which file do you want to write the corpus?
-


#########################################
#  Find Context of Regex

[RE_Input]
Corpus to be inspected
Which file contains the texts to inspect?
-

[RE_Fulltext]
Text Variable
Which variable contains the full texts to be searched?
-


[RE_ID]
Identifier Variable
Which variable contains the text identifier (optional)
-
res_none:Don't use an identifier



[RE_Expression]
Expression to be searched
Enter the regular expression and confirm. You will stay on this page
-


[RE_Case]
Case Sensitivity
Should the match be case sensitive?
-
1:Yes
0:No



########################################
# SVM Training



[SVM_Input]
Corpus with classification
Which file contains the codesheets with correct classification?
-

## use Univ_Lang and Univ_Length for langage and ngrams


[SVM_Model]
Hyperplane File
Which Json-File contains the trained SVM hyperplane?
-


[SVM_Adjust]
Hyperplane Intercept
Please indicate the intercept you wish for this hyperplane (Default is optimized for F-Score)
-


[SVM_Tryout]
Try or Test?
Do you want to test this intercept or proceed to the test?
-
try:Just try settings
test:Proceed to test



[SVM_Type]
Type of output column
Should exact values or dichotomous values be stored?
-
1:Continuous values (exact scores)
2:Dichotomous values (positive = 1)



[SVM_Textvar]
Name of the text variable
Which variable contains the full texts
-


[SVM_Classvar]
Name of the class variable
Which variable contains the information to which class a text belongs?
-


[SVM_Newvar]
Name of the new variable
The scores will be added to the Corpus. What is the name of the new variable?
-


[SVM_ID]
Name of the Identifier
Which variable contains the unique identifier of each text?
-


[SVM_Sparse]
Desired Sparsity
How many times may a word or ngram appear to be counted as possible feature?
-
1:1%-99% of texts
5:5%-95% of texts
10:10%-90% of texts


[SVM_Out]
Output File (json)
To which file should the equation for the hyperplane be written?
-


[SVM_Outtable]
Output File
To which file should the corpus with scores be written?
-


[SVMA_Input]
Input Text Corpus
Which file holds the corpus to be classified?
-


[SVMA_Folder]
Input Folder
Which folder holds the text files to be classified?



########################################
# NBC Training



## use Univ_Lang and Univ_Length for langage and ngrams
## use the SVM variables to define corpus, variables and and sparsity



[NBC_Out]
Output File (json)
To which file should the training probabilities of the Bayes Classifier be written?
-


[NBC_Model]
Probability Table
Which file holds the trained probability table for this classification?
-


[NBC_Type]
Type of output column(s)
How should the result of the classification be written?
-
1:Single value denominating the category
2:Probabilities for each category


[NBC_Newvar]
Name of the new variable
The scores will be added to the Corpus. What is the name of the new variable (Probabilities will be written with suffix)?
-


[NBC_Outtable]
Output File
To which file should the corpus with scores be written?
-



########################################
# Term Co-Occurrence


[TCO_Input]
Input Text Corpus
Please select a corpus to find co-occurrences within
-


[TCO_Keyword]
Keyword
For which word should co-occurrences be calculated?
-


[TCO_Out]
Output Table
To which file should the list of co-occurrence scores be written?
-


[TCO_Further]
Further action
Do you wish to continue the analysis of this corpus?
-
98:[choose..]
1:Yes, repeat for another keyword
2:Yes, perform term mapping
0:No further analysis



[Term_List]
List of all terms
Sorted by co-occurrence
-



[TMap_Keywords]
Terms to perform Term Mapping
Which of the following terms should be analyzed using term mapping? The number in brackets gives the co-occurrence with the keyword in %.
-


[TMap_Out]
Output R-Script
The output is an R-script to perform SSA. Where should it be stored?
-


[TMap_Type]
Distance metric
Which distance metric should be used in this SSA?
-
euclid:Euclidian Distance
sokal:Sokal Distance
invprob:Inverted Probability of Co-occurrence



########################################
# Dictionary based annotation


[Dict_Input]
Input Text Corpus
Please select a corpus to find keywords within
-


[Dict_Keyword]
Keyword List
Please select a keyword list
-


[Dict_Score]
Score Variables
Which variables indicate the score for each word?
-


[Dict_Method]
Annotation
What should be annotated?
-
occ:Occurrence of words with score not equal 0
count:Number of occurrences of words with score not equal 0
score:Mean value of scores
list:List of critical words found in the text
all:All of the above


[Dict_Ngram]
Ngram Variable
Which variable contains the words within the keyword list?
-


[Dict_Fulltext]
Fulltext Variable
Which variable contains the Fulltext within the corpus?
-



[Dict_Out]
Output Table
To which file should the annotated corpus be written?
-



########################################
# Create Term Document Matrix


[TDM_Input]
Input Text Corpus
Please select a corpus to create a TDM from
-


[TDM_Document]
Document Variable
Which variable denotes the documents for the TDM?
-


[TDM_Text]
Text Variable
Which variable holds the texts for the TDM?
-



[TDM_Wlist]
Complete Wordlist
Is there a list containing the universe of words? (increases speed)
-




[TDM_Mincas]
Minimum number of term occurrence
How many times does a term have to occur in order to be counted?`
-


[TDM_Mindoc]
Minimum number of terms per document
How many terms does a document have to contain in order to be counted?
-


[TDM_Direction]
Orientation of Output
What is the orientation of the TDM/DTM?
-
TDM:Term-Document-Matrix (Documents as rows)
DTM:Document-Term-Matrix (Terms as rows)


[TDM_Out]
Output Table
You may output the matrix to a table.
-


########################################
# Find duplicates by n-gram shingling

[NGS_Input]
Input Text Corpus
Please select a corpus to find duplicates within
-


[NGS_Fulltext]
Text Variable
Which variable holds the texts to compare?
-


[NGS_Tid]
Identifier Variable
Which variable holds the IDs of the text to identify them correctly?
-


[NGS_Nglen]
Length of shingled n-grams
How many words in series should be compared between texts?
-
4:4-grams
5:5-grams
6:6-grams
7:7-grams


[NGS_Overlap]
Length of text to compare
When a match is found, how many characters should match to count as a plagiat? Enter a number (recommended: 20)
-


[NGS_Minover]
Minimal overlap to be counted as duplicate
How many hashes should be identical in a pair of texts in order to consider them duplicates?
-


[NGS_Sym]
Redundant output
Should a pair of texts that are considered duplicates be noted as one or two cases?
-
1: One case per pairing
2: Two cases (symmetrical notation)


[NGS_Share]
Compute share of overlap
Should the length of both texts be considered and used to compute the relative overlap?
-
1: No, just count overlapping hashes
2: Yes, compute shares (slower)




[NGS_Out]
Output Table
To which file should the list of matches be written?
-






########################################
# Split collocated textfiles


[Split_Input]
Input Text File
Please select a file containing multiple texts to be fragmented to single files.
-


[Split_Sign]
Split sign
Please enter a string of characters which indicates the end of a text and the beginning of a new one.
-



[Split_Label]
Label for each document
Indicate the label which should serve as a prefix to the name of each document.
-


[Split_Number]
Number of the first document
Indicate the number of the first document. Type '00001' instead of '1' to force a fixed format.
-


[Split_Count]
Increasing or decreasing numbers
Should the enumeration run upwards or downwards? (If the first document is the most recent, choose decrease to bring them in order)
-
1:Increase number with each document
2:Decrease number with each document



[Split_Linebreaks]
Remove linebreaks
Should the linebreaks be as in the original file or should they be removed to put each paragraph in a single line?
-
1:Retain all linebreaks
2:Only retain blank lines, remove all other linebreaks


[Split_Header]
Header of the text file
Is there a header which should be printed on top of each text file? Please insert it below and use the tag <ID> if the ID of the texts should be included in the header.
-



[Split_Output]
Output Folder
Enter the folder to which the files should be exported. Leave blank to store them in the folder you execute Aeglos from.
-



########################################
# Test language/encoding


[Langtest_Input]
Input Text File
Please select a file containing one or multiple texts. Short files are recommended
-





########################################
# NCCR Populism Variables


[Populism_Input]
Target Table
Which file contains the Target Table?
-



[Populism_Output]
Output File
To which file do you want to export the dataset including the new variable?
-



########################################
# NCCR Matching Content Analysis / Survey


[Match_Respondents]
Respondent Data (Survey)
Which file contains the respondents and media usage variables?
-


[Match_Content]
Content analysis Data
Which file contains the media data to be added? It should be on text level with a Date and Weighting variable
-



[Match_Mdate]
Content Analysis: Date variable
Which variable contains the date of the text?
-
nodate:No date present / required


[Match_Mdate_Trans]
Aggregate days
Do you want to aggregate days in the content analysis?
-
no:No, use single days
week: Yes, aggregate to weeks
month: Yes, aggregate to months



[Match_Mweight]
Content Analysis: Weighting variable
Which variable contains the weighting factor for each text?
-
noweight:No weight present / required



[Match_Mvars]
Matching of variables
Which values should be added to the survey?
-



[Match_Aggmode]
Calculation of value
How should the value for each medium and date be computed?
-
mean:Mean value for each date per medium (weighted mean if specified)
sum:Sum of values for each date per medium (weighted sum if specified)
mode:Mode value on each date per medium
first:First value in the data for each date per medium



[Match_Gweight]
Survey: Global weighting variable
Does one of the variable contain a weighting factor for all media?
-
99:No Global weighting


[Match_Lweight]
Survey: Local weighting variable
Should the media be weighted according to their usage?
-
none:No weighting of media
linear:Linear weighting
grouped:Grouped weighting (Missing: 0; 1-3: 1; >3:2)


[Match_Sdate]
Survey: Date variable
Which variable contains the date of the interview?
-
99:No date present / required



[Match_Wdate]
Usage of date
How should the date be used in combination?
-
nodate:No usage of dates
before:Only add content BEFORE the survey
after:Only add content AFTER the survey
1d:Use content before survey with half-time: 1d
7d:Use content before survey with half-time: 7d (1 Week)
div:Use content before survey with disproportional weight (1/distance)
1mbefore:Use content 1 Month prior to survey (30d)
2mbefore:Use content 2 Months prior to survey (60d)
combo:Combination: before, 30d, half-time 7d


[Match_Calcmode]
Calculation of scores
How should the media data be calculated?
-
sum_sum:sum over all media days (summed)
sum_mean:sum over all media days (means)
mean_sum:mean over all media days (summed)
mean_mean:mean over all media days (means)
combo:Small Combination: sum of sums, mean of means
combo2:Full Combination: sum of sums, sum of means, mean of means, mean of sums
timeser:Werner Spezial: Regression Weight, Variability and Peaks over time (using intraday means).



[Match_Out]
Output table
To which table should the matched data be written?
-




########################################
# NCCR Populism Variables


[Hours_Input]
Text Table
Which file contains the Text Table, complete with net seconds?
-



[Hours_Output]
Output File
To which file do you want to export the summary of working hours?
-


########################################
# GGCRISI


[GGCRISI_Input]
Directory containing data files
In which directory are the angrist data files stored? The files should be named like the original Angrist files (e.g.:_Text.txt)
-



[GGCRISI_Output]
Output File
To which file do you want to export the dataset including all data?
-


###############################################################################################
###############
############### Fehlermeldungen und sonstige Meldungen
###############

[Otherart]
All done. Do you want to proceed with another data manipulation?
The file is created and may be used for subsequent data processing.
-
1:Yes
2:No


[Err_Msg]
-
-
-
Caution01:Warning!#If you go back one step further, the current function aborts and all data will be removed from memory.##Are you sure you want to go back to the start screen and reset Nogrod?
Caution02:This action will remove the text from the sample. Only discard texts that do not have anything to do with elections, immigration, or labor market policies.##Are you sure you want to discard this text?
Info01:Your insecurity has been transmitted. You may now continue coding.
Invalid-Selection01:No Item was selected from the list. Please select at least one item to continue.
Invalid-Selection02:Invalid selection. Please select an option to continue.##Variable:
Invalid-Selection03:Invalid Characters entered. Please do not use special characters.
Invalid-Selection04:Invalid Filename.#Please enter a filename or browse for a file.
Invalid-Selection05:Invalid number of variables#Please select the same number of variables for the keytable as for the main table.
Invalid-Selection06:No text entered. Please enter a value to continue.
Invalid-Selection07:No number entered. Please enter a numeric value.
Invalid-Selection08:Invalid regular expression
Runtime-Error01:This action is impossible.##Please contact Martin Wettstein to find out why.
Runtime-Error02:There are no more items in the Todo-List or the Todo-List does not exist. Please contact the operational staff to get new texts or fix this problem.##If you do know the ID of your next text you may enter it manually.
Runtime-Error03:Please enter the text identifier. You may not continue coding without a valid identifier.
Runtime-Error04:The specified text was not found in the text-folder. Please check spelling.
Runtime-Error05:Please select Source and proceed to the next page before using this feature.##The highlighting of relevant words will depend on the country of origin of your Medium
Runtime-Error06:No Text found. Do you want to continue without text display?
No Files:Warning! No files with expected extensions in this directory!
No Variables:Warning!#In this file there are less than 2 variables. You probably picked the wrong file or the wrong separator.
Method Fail:Warning!#If no relation variable is present, this function may not be used.##Without any relation variable you may only use 'count' and 'dichotomous'.
File Incomplete:Warning!#The File you have just opened does not contain equal numbers of cases for each variable. It may be corrupted.##Certain Calculations may not be possible. View Text output for details.
File not found!:Error##File could not be loaded.##Details:#


[Location]
-
-
-
Current:You are coding at the moment:
Stat:Statement of:
Tow:Toward:
End:Nogrod was terminated. You may close the window now.




###########Sonderzeichen, die hier nicht vorkommen sollten: „"–